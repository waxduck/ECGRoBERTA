{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1905968,"sourceType":"datasetVersion","datasetId":1136210},{"sourceId":11883994,"sourceType":"datasetVersion","datasetId":7467563},{"sourceId":12036167,"sourceType":"datasetVersion","datasetId":7267352}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1278.614982,"end_time":"2025-05-29T15:57:26.662035","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-29T15:36:08.047053","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install neurokit2","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:13:18.172222Z","iopub.execute_input":"2025-06-07T17:13:18.172482Z","iopub.status.idle":"2025-06-07T17:13:22.871986Z","shell.execute_reply.started":"2025-06-07T17:13:18.172447Z","shell.execute_reply":"2025-06-07T17:13:22.871140Z"},"papermill":{"duration":5.150931,"end_time":"2025-05-29T15:36:17.764939","exception":false,"start_time":"2025-05-29T15:36:12.614008","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install wfdb","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:13:22.873507Z","iopub.execute_input":"2025-06-07T17:13:22.873757Z","iopub.status.idle":"2025-06-07T17:13:26.310546Z","shell.execute_reply.started":"2025-06-07T17:13:22.873734Z","shell.execute_reply":"2025-06-07T17:13:26.309806Z"},"papermill":{"duration":3.490758,"end_time":"2025-05-29T15:36:21.261142","exception":false,"start_time":"2025-05-29T15:36:17.770384","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pyedflib","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:13:26.311416Z","iopub.execute_input":"2025-06-07T17:13:26.311669Z","iopub.status.idle":"2025-06-07T17:13:50.203541Z","shell.execute_reply.started":"2025-06-07T17:13:26.311639Z","shell.execute_reply":"2025-06-07T17:13:50.202555Z"},"papermill":{"duration":24.369647,"end_time":"2025-05-29T15:36:45.636166","exception":false,"start_time":"2025-05-29T15:36:21.266519","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport ast\nimport matplotlib.pyplot as plt\nimport neurokit2 as nk\nimport json\nimport os\n# import wfdb\nimport pickle\nimport random\nfrom scipy.signal import find_peaks\nimport mne\nimport pyedflib\nfrom tqdm import tqdm\nfrom scipy.signal import butter, filtfilt","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:13:50.207521Z","iopub.execute_input":"2025-06-07T17:13:50.207710Z","iopub.status.idle":"2025-06-07T17:13:55.261707Z","shell.execute_reply.started":"2025-06-07T17:13:50.207690Z","shell.execute_reply":"2025-06-07T17:13:55.260928Z"},"papermill":{"duration":5.483338,"end_time":"2025-05-29T15:36:51.125432","exception":false,"start_time":"2025-05-29T15:36:45.642094","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_edf_record(file_path):\n    try:\n        f = pyedflib.EdfReader(file_path)\n        n_channels = f.signals_in_file\n        channel_labels = f.getSignalLabels()\n        signals = np.vstack([f.readSignal(i) for i in range(n_channels)])\n        sfreq = f.getSampleFrequency(0)\n        f._close()\n        return signals, channel_labels, sfreq\n    except Exception as e:\n        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file_path}: {e}\")\n        return None, None, None\n\ndef extract_periods(signal, sfreq, num_periods=1, distance_sec=0.6):\n    peaks, _ = find_peaks(signal, distance=int(distance_sec * sfreq * 0.8))\n    if len(peaks) < num_periods + 1:\n        raise ValueError(\"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–∏–∫–æ–≤\")\n    periods = []\n    for i in range(num_periods):\n        start = peaks[i]\n        end = peaks[i+1]\n        half = int((end-start)/2)\n        periods.append(signal[end-half:end+half])\n    return periods\n\ndef process_record(record_path, target_channels):\n    signals, channel_labels, sfreq = read_edf_record(record_path) \n    lowcut = 0.6  \n    highcut = 40\n    order = 1  \n    nyquist_freq = 0.5 * sfreq\n    low = lowcut / nyquist_freq\n    high = highcut / nyquist_freq\n    \n    if signals is None or channel_labels is None:\n        print(f\"‚ùå –ü—Ä–æ–ø—É—Å–∫: {record_path} ‚Äî —Å–∏–≥–Ω–∞–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n        return None\n    if not all(ch in channel_labels for ch in target_channels):\n        print(f\"‚ùå –ü—Ä–æ–ø—É—Å–∫: {record_path} ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–∞–Ω–∞–ª—ã: {[ch for ch in target_channels if ch not in channel_labels]}\")\n        return None\n    if signals is None or channel_labels is None:\n        return None\n    if not all(ch in channel_labels for ch in target_channels):\n        return None\n    ecg_pieces = []\n    for ch in target_channels:\n        idx = channel_labels.index(ch)\n        # print(f'channel = {ch}, index = {idx}')\n        ch_data = signals[idx]\n        # ch_data = (ch_data - np.mean(ch_data)) / np.std(ch_data)\n        b, a = butter(order, [low, high], btype='bandpass')\n        ch_dat = filtfilt(b, a, ch_data)\n        try:\n            periods = extract_periods(ch_dat, sfreq, num_periods=1)\n            ecg_pieces.append(periods[0])\n        except Exception as e:\n            print(f\"–û—à–∏–±–∫–∞: {e}\")\n            return None\n    return np.hstack(ecg_pieces).tolist()","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:14:19.255759Z","iopub.execute_input":"2025-06-07T17:14:19.256410Z","iopub.status.idle":"2025-06-07T17:14:19.266136Z","shell.execute_reply.started":"2025-06-07T17:14:19.256387Z","shell.execute_reply":"2025-06-07T17:14:19.265426Z"},"papermill":{"duration":0.017558,"end_time":"2025-05-29T15:36:51.149050","exception":false,"start_time":"2025-05-29T15:36:51.131492","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mne.set_log_level('WARNING')\n\nbase_folder = '/kaggle/input/low-ejection-fraction'\nedf_folders = [f'{i}/{i}' for i in range(1, 12)]\ntarget_channels = ['ECG I', 'ECG II', 'ECG V1', 'ECG V2', 'ECG V3', 'ECG V4', 'ECG V5', 'ECG V6']\n\n# –ß–∏—Ç–∞–µ–º lef_names.csv (–±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞)\nlef_df = pd.read_csv(f'{base_folder}/lef_names.csv', header=None)\nlef_names = set(lef_df[0].apply(lambda x: os.path.splitext(os.path.basename(str(x).strip()))[0]))\nprint(\"–ö–æ–ª–≤–æ —Å—Ç—Ä–æ–∫ –≤ lef_names.csv:\", len(lef_names))\n\n# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ .edf —Ñ–∞–π–ª—ã\nrecord_paths = dict()\nfor folder in edf_folders:\n    folder_path = os.path.join(base_folder, folder)\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith('.edf'):\n                name = os.path.splitext(file)[0]\n                record_paths[name] = os.path.join(root, file)\n\nprint(f\"–ù–∞–π–¥–µ–Ω–æ .edf —Ñ–∞–π–ª–æ–≤: {len(record_paths)}\")\nprint(\"–ü—Ä–∏–º–µ—Ä—ã:\", list(record_paths.items())[:5])\n\nall_records = list(record_paths.keys())\n\n# –î–µ–ª–∏–º –Ω–∞ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∏ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è\npos_names = list(lef_names & set(all_records))\nprint(f\"–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö: {len(pos_names)}\")\nneg_candidates = list(set(all_records) - lef_names)\nrandom.shuffle(neg_candidates)\nneg_names = neg_candidates[:len(pos_names)]\n\nused_names = set(pos_names + neg_names)\nremaining_names = list(set(all_records) - used_names)\n\n# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏ —Å–±–æ—Ä\ntune_data = []\ntune_labels = []\ntune_files_pos = []\ntune_files_neg = []\n\nprint(\"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ ecg_tune.pkl...\")\nfor name, label in tqdm([(n, 1) for n in pos_names] + [(n, 0) for n in neg_names]):\n    sig = process_record(record_paths[name], target_channels)\n    if sig:\n        tune_data.append(sig)\n        tune_labels.append(label)\n        if label == 1:\n            tune_files_pos.append(name)\n        else:\n            tune_files_neg.append(name)\n\ndf_tune = pd.DataFrame({'signal': tune_data, 'label': tune_labels})\nwith open('ecg_tune.pkl', 'wb') as f:\n    pickle.dump(df_tune, f)\n\n# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è\nprint(\"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ ecg_data.pkl...\")\ndata_data = []\ndata_files = []\nfor name in tqdm(remaining_names):\n    sig = process_record(record_paths[name], target_channels)\n    if sig:\n        data_data.append(sig)\n        data_files.append(name)\n\ndf_data = pd.DataFrame({'signal': data_data})\nwith open('ecg_data.pkl', 'wb') as f:\n    pickle.dump(df_data, f)\n\n# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\nprint(f\"\\n‚úÖ ecg_tune.pkl: {len(tune_data)} –∑–∞–ø–∏—Å–µ–π (–ø–æ–ª–æ–∂–∏—Ç: {len(tune_files_pos)}, –æ—Ç—Ä–∏—Ü–∞—Ç: {len(tune_files_neg)})\")\nprint(f\"–ü—Ä–∏–º–µ—Ä—ã –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö: {tune_files_pos[:5]}\")\nprint(f\"–ü—Ä–∏–º–µ—Ä—ã –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã—Ö: {tune_files_neg[:5]}\")\nprint(f\"\\n‚úÖ ecg_data.pkl: {len(data_data)} –∑–∞–ø–∏—Å–µ–π\")\nprint(f\"–ü—Ä–∏–º–µ—Ä—ã –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è: {data_files[:5]}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:14:21.733714Z","iopub.execute_input":"2025-06-07T17:14:21.733993Z","iopub.status.idle":"2025-06-07T17:18:59.959160Z","shell.execute_reply.started":"2025-06-07T17:14:21.733973Z","shell.execute_reply":"2025-06-07T17:18:59.958540Z"},"papermill":{"duration":252.662948,"end_time":"2025-05-29T15:41:03.817532","exception":false,"start_time":"2025-05-29T15:36:51.154584","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import wfdb\n\nbase_folder = '/kaggle/input/ptb-xl-dataset/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/records500'\nphysionet_folders = ['00000', '01000', '02000', '03000', '04000', '05000', '06000', '07000', '08000', '09000']\ntarget_channels_physio = ['I', 'II', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n\ndef read_physionet_record(record_path):\n    try:\n        record = wfdb.rdrecord(record_path)\n        channel_labels = record.sig_name\n        signals = record.p_signal.T  # —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –±—ã–ª–æ [n_channels, n_samples]\n        sfreq = record.fs\n        return signals, channel_labels, sfreq\n    except Exception as e:\n        print(f\"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {record_path}: {e}\")\n        return None, None, None\n\ndef process_physio_record(record_path, target_channels):\n    signals, channel_labels, sfreq = read_physionet_record(record_path)\n    lowcut = 0.6  \n    highcut = 40\n    order = 1  \n    nyquist_freq = 0.5 * sfreq\n    low = lowcut / nyquist_freq\n    high = highcut / nyquist_freq\n\n    if signals is None or channel_labels is None:\n        print(f\"‚ùå –ü—Ä–æ–ø—É—Å–∫: {record_path} ‚Äî —Å–∏–≥–Ω–∞–ª—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n        return None\n    if not all(ch in channel_labels for ch in target_channels):\n        print(f\"‚ùå –ü—Ä–æ–ø—É—Å–∫: {record_path} ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–∞–Ω–∞–ª—ã: {[ch for ch in target_channels if ch not in channel_labels]}\")\n        return None\n    ecg_pieces = []\n    for ch in target_channels:\n        idx = channel_labels.index(ch)\n        ch_data = signals[idx]\n        b, a = butter(order, [low, high], btype='bandpass')\n        ch_dat = filtfilt(b, a, ch_data)\n        try:\n            periods = extract_periods(ch_dat, sfreq, num_periods=1)\n            ecg_pieces.append(periods[0])\n        except Exception as e:\n            print(f\"–û—à–∏–±–∫–∞: {e}\")\n            return None\n    return np.hstack(ecg_pieces).tolist()\n\n# –°–±–æ—Ä –ø—É—Ç–µ–π –∫ .dat/.hea\nphysio_record_paths = dict()\nfor folder in physionet_folders:\n    folder_path = os.path.join(base_folder, folder)\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            if file.endswith('.hea'):\n                name = os.path.splitext(file)[0]\n                physio_record_paths[name] = os.path.join(root, name)\n\nprint(f\"–ù–∞–π–¥–µ–Ω–æ physio-—Ñ–∞–π–ª–æ–≤: {len(physio_record_paths)}\")\nprint(\"–ü—Ä–∏–º–µ—Ä—ã:\", list(physio_record_paths.items())[:5])\n\n# –û–±—Ä–∞–±–æ—Ç–∫–∞ physio –¥–∞–Ω–Ω—ã—Ö\nphysio_data = []\nphysio_files = []\nprint(\"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ physio –¥–∞–Ω–Ω—ã—Ö...\")\nfor name, path in tqdm(physio_record_paths.items()):\n    sig = process_physio_record(path, target_channels_physio)\n    if sig:\n        physio_data.append(sig)\n        physio_files.append(name)\n\ndf_physio = pd.DataFrame({'signal': physio_data})\nprint(f\"\\n‚úÖ df_physio: {len(df_physio)} –∑–∞–ø–∏—Å–µ–π\")\nprint(f\"–ü—Ä–∏–º–µ—Ä—ã: {physio_files[:5]}\")\n\n# –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å df_data (–∏–∑ EDF)\ndf_data_combined = pd.concat([df_data, df_physio], ignore_index=True)\n\nwith open('ecg_data_combined.pkl', 'wb') as f:\n    pickle.dump(df_data_combined, f)\n\nprint(f\"\\n‚úÖ ecg_data_combined.pkl: {len(df_data_combined)} –∑–∞–ø–∏—Å–µ–π\")\n","metadata":{"execution":{"iopub.status.busy":"2025-06-07T17:18:59.960512Z","iopub.execute_input":"2025-06-07T17:18:59.960718Z","execution_failed":"2025-06-07T18:35:53.284Z"},"papermill":{"duration":599.791756,"end_time":"2025-05-29T15:51:03.702825","exception":false,"start_time":"2025-05-29T15:41:03.911069","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df_tune.to_pickle('ecg_tune.pkl')\n# df_data.to_pickle('ecg_data.pkl')","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:04.284611Z","iopub.status.busy":"2025-05-29T15:51:04.284086Z","iopub.status.idle":"2025-05-29T15:51:04.443788Z","shell.execute_reply":"2025-05-29T15:51:04.442881Z"},"papermill":{"duration":0.420398,"end_time":"2025-05-29T15:51:04.445389","exception":false,"start_time":"2025-05-29T15:51:04.024991","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# df = pd.read_csv('ecg_data.csv')\ndf = df_data_combined\nprint(df.shape)\ndf.head(5)","metadata":{"execution":{"execution_failed":"2025-06-07T18:35:53.303Z"},"papermill":{"duration":0.284161,"end_time":"2025-05-29T15:51:04.988820","exception":false,"start_time":"2025-05-29T15:51:04.704659","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"n = np.linspace(0, 100, len(df.iloc[2000][0]))\nplt.plot(n, df.iloc[2000][0])","metadata":{"execution":{"execution_failed":"2025-06-07T18:35:53.305Z"},"papermill":{"duration":0.537535,"end_time":"2025-05-29T15:51:05.844150","exception":false,"start_time":"2025-05-29T15:51:05.306615","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df.iloc[11000][0])","metadata":{"execution":{"execution_failed":"2025-06-07T18:35:53.306Z"},"papermill":{"duration":0.26713,"end_time":"2025-05-29T15:51:06.368385","exception":false,"start_time":"2025-05-29T15:51:06.101255","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def resample_signal(row):\n    original_signal = row['signal']\n    resampled_signal = nk.signal_resample(original_signal, sampling_rate=500, desired_sampling_rate= 250, method=\"FFT\")\n    return pd.Series({'signal': resampled_signal})","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:06.952200Z","iopub.status.busy":"2025-05-29T15:51:06.951920Z","iopub.status.idle":"2025-05-29T15:51:06.955848Z","shell.execute_reply":"2025-05-29T15:51:06.955241Z"},"papermill":{"duration":0.264672,"end_time":"2025-05-29T15:51:06.956877","exception":false,"start_time":"2025-05-29T15:51:06.692205","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_db_new = df\nresampled_df = total_db_new.apply(resample_signal, axis=1)\ndel total_db_new\ntotal_db_new = resampled_df","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:07.470260Z","iopub.status.busy":"2025-05-29T15:51:07.469976Z","iopub.status.idle":"2025-05-29T15:51:34.356987Z","shell.execute_reply":"2025-05-29T15:51:34.356334Z"},"papermill":{"duration":27.145666,"end_time":"2025-05-29T15:51:34.358379","exception":false,"start_time":"2025-05-29T15:51:07.212713","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(total_db_new)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:34.931582Z","iopub.status.busy":"2025-05-29T15:51:34.931292Z","iopub.status.idle":"2025-05-29T15:51:34.935661Z","shell.execute_reply":"2025-05-29T15:51:34.935122Z"},"papermill":{"duration":0.322817,"end_time":"2025-05-29T15:51:34.936746","exception":false,"start_time":"2025-05-29T15:51:34.613929","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, temp_df = train_test_split(total_db_new, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=(2/3), random_state=42)\n\ntrain_df.reset_index(drop=True, inplace=True)\nval_df.reset_index(drop=True, inplace=True)\ntest_df.reset_index(drop=True, inplace=True)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:35.456165Z","iopub.status.busy":"2025-05-29T15:51:35.455887Z","iopub.status.idle":"2025-05-29T15:51:35.465740Z","shell.execute_reply":"2025-05-29T15:51:35.465204Z"},"papermill":{"duration":0.272494,"end_time":"2025-05-29T15:51:35.466914","exception":false,"start_time":"2025-05-29T15:51:35.194420","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_max_min(current_df):\n  min_value = current_df['signal'].apply(lambda x: min(x)).min()\n  max_value = current_df['signal'].apply(lambda x: max(x)).max()\n  return min_value, max_value\n\nmin_train_df, max_train_df = find_max_min(train_df)\nprint(min_train_df, max_train_df)\n\nmin_val_df, max_val_df = find_max_min(val_df)\nprint(min_val_df, max_val_df)\n\nmin_test_df, max_test_df = find_max_min(test_df)\nprint(min_test_df, max_test_df)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:36.039076Z","iopub.status.busy":"2025-05-29T15:51:36.038289Z","iopub.status.idle":"2025-05-29T15:51:43.650632Z","shell.execute_reply":"2025-05-29T15:51:43.649774Z"},"papermill":{"duration":7.872424,"end_time":"2025-05-29T15:51:43.651962","exception":false,"start_time":"2025-05-29T15:51:35.779538","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df['signal'] = train_df['signal'].apply(lambda x: [(item - min_train_df) / (max_train_df - min_train_df) for item in x])\n\nval_df['signal'] = val_df['signal'].apply(lambda x: [(item - min_val_df) / (max_val_df - min_val_df) for item in x])\n\ntest_df['signal'] = test_df['signal'].apply(lambda x: [(item - min_test_df) / (max_test_df - min_test_df) for item in x])","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:44.172235Z","iopub.status.busy":"2025-05-29T15:51:44.171276Z","iopub.status.idle":"2025-05-29T15:51:58.037615Z","shell.execute_reply":"2025-05-29T15:51:58.037020Z"},"papermill":{"duration":14.127971,"end_time":"2025-05-29T15:51:58.039011","exception":false,"start_time":"2025-05-29T15:51:43.911040","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Quantizer","metadata":{"papermill":{"duration":0.320026,"end_time":"2025-05-29T15:51:58.617620","exception":false,"start_time":"2025-05-29T15:51:58.297594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class DiffQuantizer:\n    def __init__(self, alphabet_size, average_over=1, filter=False, breakpoints=None, use_diffs=True):\n\n        self.alphabet_size = alphabet_size\n        self.average_over = average_over\n        self.use_filter = filter\n        self.breakpoints = breakpoints\n        self.use_diffs = use_diffs\n        # print('self.breakpoints:',self.breakpoints)\n\n    def preprocess(self, tmp):\n        if self.average_over != 1:\n            tmp = self._average_over_n(tmp, self.average_over)\n\n        if self.use_filter:\n            tmp = self._filter_signal(tmp)\n\n        if self.use_diffs:\n            tmp = self._diff_signal(tmp)\n\n        return tmp\n\n    def perform_quantization(self, tmp, breakpoints=None):\n        self.breakpoints = breakpoints\n        # print('perform_quantization, self.breakpoints:',self.breakpoints)\n        tmp = self.preprocess(tmp)\n        result = self._quantize_with_breakpoints(tmp)\n        return result\n\n    def learn_breakpoints(self, arr):\n        res = self.preprocess(arr)\n\n        sorted_array = np.sort(res)\n\n        length = len(sorted_array)\n\n        probs = [1 / self.alphabet_size for _ in range(self.alphabet_size)]\n        cum_sum_breakpoints = [int(sum(probs[0:i + 1]) * length - 1) for i in range(len(probs))]\n        cum_sum_breakpoint_values = sorted_array[cum_sum_breakpoints]\n\n        cum_sum_breakpoint_values[-1] = 1e+100\n\n        self.breakpoints = cum_sum_breakpoint_values\n        # print('learn_breakpoints,self.breakpoints',self.breakpoints)\n\n        return cum_sum_breakpoint_values\n\n    # vectorized use\n    @staticmethod\n    def _breakpoint_to_letter(float_num, breakpoints):\n        # print('float_num:',float_num,'breakpoints:',breakpoints)\n        # print(list((breakpoints.index(obj) for obj in breakpoints if float_num < obj)))\n        int_val = next((breakpoints.index(obj) for obj in breakpoints if float_num < obj))\n        # print(int_val,list((breakpoints.index(obj) for obj in breakpoints if float_num < obj)))\n        # A + int_val\n        return chr(65 + int_val)\n\n    def _quantize_with_breakpoints(self, tmp):\n        breakpoints = self.breakpoints\n        vect_breakpoint_to_letter = np.vectorize(self._breakpoint_to_letter, excluded=['breakpoints'])\n        # print(tmp,breakpoints,self._breakpoint_to_letter,vect_breakpoint_to_letter)\n        tmp = vect_breakpoint_to_letter(tmp, breakpoints=list(breakpoints))\n        # tmp = vect_breakpoint_to_letter(tmp, breakpoints=breakpoints)\n        return tmp\n\n    @staticmethod\n    def _read_csv_file(input_file):\n        tmp_file_content = pd.read_csv(input_file, sep=\"\\n\", header=None, dtype=np.float64)\n        return np.array(tmp_file_content)\n\n    ## @staticmethod\n    # def _filter_signal(tmp):\n    #     return butter_lowpass_filter(tmp)\n\n    @staticmethod\n    def _average_over_n(tmp, n):\n        return np.array([np.average(tmp[i:i + n]) for i in range(0, len(tmp), n)])\n\n    @staticmethod\n    def _diff_signal(tmp):\n        res = np.diff(tmp)\n        return np.insert(res, 0, 0.0)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:59.140780Z","iopub.status.busy":"2025-05-29T15:51:59.140464Z","iopub.status.idle":"2025-05-29T15:51:59.155668Z","shell.execute_reply":"2025-05-29T15:51:59.154904Z"},"papermill":{"duration":0.27981,"end_time":"2025-05-29T15:51:59.156934","exception":false,"start_time":"2025-05-29T15:51:58.877124","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import math\nimport csv\n\nclass Preprocessing():\n\n  def __init__(self, input_file, discretizition_factor, max_window_size):\n    self.input_file = input_file\n    self.discretizition_factor = discretizition_factor\n    self.max_window_size = max_window_size\n\n\n  def create_window(self):\n\n    ecg_window = [] #ecg_window: list of windows\n\n    mlen=0\n    ecg_list = self.input_file['signal']\n    if len(ecg_list) > mlen:\n      mlen= len(ecg_list)\n\n    if mlen > self.max_window_size:\n      window_size = self.max_window_size\n    else:\n      window_size = mlen\n\n    num_lines = math.floor(len(ecg_list)/window_size) #in this case: 1\n\n    for i in range(num_lines):\n      tmp_list = ecg_list[i*window_size:(i+1)*window_size]\n      ecg_window.append(tmp_list)\n\n    return ecg_window\n\n  def change_to_alphabet(self, quantizer, normalized_list):\n    qtz_signal = []\n    qtz = quantizer\n    for i in range(len(normalized_list)): #i is for each line\n      r = qtz.perform_quantization(np.array(normalized_list[i]),breakpoints=qtz.breakpoints)\n      # print('result:',r.shape)\n      # make r from list of chars  to string a chars by ''.joint(r)\n      qtz_signal.append(''.join(r))\n\n    return qtz_signal","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:51:59.687674Z","iopub.status.busy":"2025-05-29T15:51:59.687089Z","iopub.status.idle":"2025-05-29T15:51:59.693863Z","shell.execute_reply":"2025-05-29T15:51:59.693062Z"},"papermill":{"duration":0.27896,"end_time":"2025-05-29T15:51:59.695051","exception":false,"start_time":"2025-05-29T15:51:59.416091","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def discretization_lloyd_max(discretizition_factor, total_data):\n  qtz_signal = []\n  qtz=DiffQuantizer(alphabet_size=discretizition_factor,breakpoints=None,use_diffs=False)\n  qtz.learn_breakpoints(np.array(total_data))\n  return qtz","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:52:00.276077Z","iopub.status.busy":"2025-05-29T15:52:00.275773Z","iopub.status.idle":"2025-05-29T15:52:00.279567Z","shell.execute_reply":"2025-05-29T15:52:00.279076Z"},"papermill":{"duration":0.264936,"end_time":"2025-05-29T15:52:00.280688","exception":false,"start_time":"2025-05-29T15:52:00.015752","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def run_Preprocessing(db, max_window_size=4000, discretizition_factor=100):\n    discretizition_factor = discretizition_factor\n    max_window_size = max_window_size\n    nl_list, total_data = [], []\n    r_list = []\n\n    for n in range(len(db)):\n      pre = Preprocessing(db.loc[n], discretizition_factor, max_window_size)\n      nl = pre.create_window()\n      nl_list.append(nl)\n\n    for i in range(len(nl_list)):\n        total_data.extend(nl_list[i][0])\n\n    quantize_max_lloyd_on_total_data = discretization_lloyd_max(discretizition_factor, total_data)\n\n    for n in range(len(db)):\n      pre = Preprocessing(db.loc[n], discretizition_factor, max_window_size)\n      nl = pre.create_window()\n      r = pre.change_to_alphabet(quantize_max_lloyd_on_total_data, nl)\n      r_list.extend(r)\n    print(n, \" : done\")\n\n    return r_list","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:52:00.820238Z","iopub.status.busy":"2025-05-29T15:52:00.819961Z","iopub.status.idle":"2025-05-29T15:52:00.825826Z","shell.execute_reply":"2025-05-29T15:52:00.825082Z"},"papermill":{"duration":0.268252,"end_time":"2025-05-29T15:52:00.826985","exception":false,"start_time":"2025-05-29T15:52:00.558733","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Before preprocessing:')\nprint(len(train_df))\nprint(len(val_df))\nprint(len(test_df))","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:52:01.401090Z","iopub.status.busy":"2025-05-29T15:52:01.400785Z","iopub.status.idle":"2025-05-29T15:52:01.405460Z","shell.execute_reply":"2025-05-29T15:52:01.404619Z"},"papermill":{"duration":0.265494,"end_time":"2025-05-29T15:52:01.406598","exception":false,"start_time":"2025-05-29T15:52:01.141104","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r_list_train = run_Preprocessing(db=train_df, max_window_size=4000, discretizition_factor=100)\n\nr_list_val = run_Preprocessing(db=val_df, max_window_size=4000, discretizition_factor=100)\n\nr_list_test = run_Preprocessing(db=test_df, max_window_size=4000, discretizition_factor=100)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:52:01.925450Z","iopub.status.busy":"2025-05-29T15:52:01.924866Z","iopub.status.idle":"2025-05-29T15:57:19.086209Z","shell.execute_reply":"2025-05-29T15:57:19.085356Z"},"papermill":{"duration":317.681633,"end_time":"2025-05-29T15:57:19.345865","exception":false,"start_time":"2025-05-29T15:52:01.664232","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('After preprocessing:')\nprint(len(r_list_train))\nprint(len(r_list_val))\nprint(len(r_list_test))","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:57:19.928444Z","iopub.status.busy":"2025-05-29T15:57:19.928165Z","iopub.status.idle":"2025-05-29T15:57:19.932514Z","shell.execute_reply":"2025-05-29T15:57:19.931748Z"},"papermill":{"duration":0.329384,"end_time":"2025-05-29T15:57:19.933560","exception":false,"start_time":"2025-05-29T15:57:19.604176","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ecg_train = pd.DataFrame(r_list_train, columns=['signal'])\necg_val = pd.DataFrame(r_list_val, columns=['signal'])\necg_test = pd.DataFrame(r_list_test, columns=['signal'])\nprint(ecg_train.shape)\necg_train.head(10)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:57:20.453004Z","iopub.status.busy":"2025-05-29T15:57:20.452250Z","iopub.status.idle":"2025-05-29T15:57:20.469413Z","shell.execute_reply":"2025-05-29T15:57:20.468754Z"},"papermill":{"duration":0.27499,"end_time":"2025-05-29T15:57:20.470408","exception":false,"start_time":"2025-05-29T15:57:20.195418","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ecg_train.to_csv('ecg_train.csv', sep='\\t', index=False)\necg_val.to_csv('ecg_val.csv', sep='\\t', index=False)\necg_test.to_csv('ecg_test.csv', sep='\\t', index=False)","metadata":{"execution":{"iopub.execute_input":"2025-05-29T15:57:20.981569Z","iopub.status.busy":"2025-05-29T15:57:20.980902Z","iopub.status.idle":"2025-05-29T15:57:22.805462Z","shell.execute_reply":"2025-05-29T15:57:22.804671Z"},"papermill":{"duration":2.079792,"end_time":"2025-05-29T15:57:22.806963","exception":false,"start_time":"2025-05-29T15:57:20.727171","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.257329,"end_time":"2025-05-29T15:57:23.381366","exception":false,"start_time":"2025-05-29T15:57:23.124037","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}